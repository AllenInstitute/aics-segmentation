{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special playground for the workshop: 3D Quantitative Visualization of Fluorescently Labeled Cells (8am to 6pm Oct 1, 2019)\t\n",
    "\n",
    "This notebook contains the workflow for the example image provided in the workshop.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Min-max intensity normalization / Auto-contrast\n",
    "* 3D Gaussian smoothing \n",
    "* 2D filament filter \n",
    "* Size thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.1\n",
    "#==========\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage, omeTifWriter                            \n",
    "\n",
    "# function for core algorithm\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_3d, edge_preserving_smoothing_3d\n",
    "from skimage.morphology import remove_small_objects     # function for post-processing (size filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.2\n",
    "#==========\n",
    "\n",
    "FILE_NAME = '../demo_data/TOM20_demo_data.tif'\n",
    "reader = AICSImage(FILE_NAME) \n",
    "IMG = reader.data.astype(np.float32)\n",
    "\n",
    "print(IMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.3\n",
    "#==========\n",
    "\n",
    "N_CHANNELS = IMG.shape[1]\n",
    "MID_SLICE = np.int(0.5*IMG.shape[2])\n",
    "\n",
    "fig, ax = plt.subplots(1, N_CHANNELS, figsize=(18,16), dpi=72, facecolor='w', edgecolor='k')\n",
    "if N_CHANNELS>1:\n",
    "    for channel in range(N_CHANNELS):\n",
    "        ax[channel].axis('off')\n",
    "        ax[channel].imshow(IMG[0,channel,MID_SLICE,:,:], cmap=plt.cm.gray)\n",
    "else:\n",
    "    ax.axis('off')\n",
    "    ax.imshow(IMG[0,0,MID_SLICE,:,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.4\n",
    "#==========\n",
    "\n",
    "#####################\n",
    "structure_channel = 0\n",
    "#####################\n",
    "\n",
    "struct_img0 = IMG[0,structure_channel,:,:,:].copy()\n",
    "view(single_fluorescent_view(struct_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * `intensity_scaling_param = [3.5, 15]`\n",
    "\n",
    "\n",
    "* **Smoothing** \n",
    "\n",
    "    * `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.5\n",
    "#==========\n",
    "\n",
    "# Parameters\n",
    "intensity_scaling_param = [3.5, 15]\n",
    "gaussian_smoothing_sigma = 1\n",
    "\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with 2d gaussian filter slice by slice \n",
    "structure_img_smooth = image_smoothing_gaussian_3d(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.6\n",
    "#==========\n",
    "\n",
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "We have a function to give you some suggestions. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL II.7\n",
    "#==========\n",
    "\n",
    "from aicssegmentation.core.pre_processing_utils import suggest_normalization_param\n",
    "suggest_normalization_param(struct_img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply 2d filament filter \n",
    "\n",
    "* Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "    * `scale_x` is set based on the estimated width of your target curvilinear shape. For example, if visually the width of the objects is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have objects of very different sizes.  \n",
    "    * `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf fatter segmentation, while larger `cutoff_x` could be less permisive and yield less objects and slimmer segmentation. \n",
    "\n",
    "\n",
    "* `f2_param = [[1.5, 0.16]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.1\n",
    "#===========\n",
    "\n",
    "f2_param = [[1.5, 0.16]]\n",
    "\n",
    "bw = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.2\n",
    "#===========\n",
    "\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "\n",
    "You can select an ROI in above visualization; otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.3\n",
    "#===========\n",
    "\n",
    "view(seg_fluo_side_by_side(struct_img,bw,roi=['ROI',viewer_bw.roi_slice()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the segmentation satisfactory? Here are some possible criteria:\n",
    "\n",
    "--------------------------\n",
    "* Is there any object should be detected but not? Try to reduce `cutoff_x`\n",
    "* Is there any object should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented width of the objects is fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any object that should be solid but segmented as fragmented pieces? Try to increase `scale_x`\n",
    "* Are you observing objects with very different width? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.4\n",
    "#===========\n",
    "\n",
    "minArea = 5\n",
    "\n",
    "seg = remove_small_objects(bw>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.5\n",
    "#===========\n",
    "\n",
    "viewer_final = view(segmentation_quick_view(seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "You can select an ROI in above visualization; otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.5\n",
    "#===========\n",
    "\n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a ome.tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========\n",
    "# CELL III.6\n",
    "#===========\n",
    "\n",
    "seg = seg >0\n",
    "out=seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "writer = omeTifWriter.OmeTifWriter('_path_')\n",
    "writer.save(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "First we import necessary packages and perform connected components labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.1\n",
    "#==========\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seg_labeled = measure.label(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop over each connected component and we count how many pixels it contains. Everything is stored as a dataframe. The first 5 lines of the resulting dataframe is shown after the computation is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.2\n",
    "#==========\n",
    "\n",
    "df = []\n",
    "for cc in range(1,seg_labeled.max()+1):\n",
    "        df.append({\n",
    "            \"label\": cc,\n",
    "            \"volume\": (seg_labeled==cc).sum()\n",
    "        })\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total volume (in pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.3\n",
    "#==========\n",
    "\n",
    "df.volume.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.4\n",
    "#==========\n",
    "\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average volume per connected component (in pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.5\n",
    "#==========\n",
    "\n",
    "df.volume.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Std of volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# CELL IV.6\n",
    "#==========\n",
    "\n",
    "df.volume.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
